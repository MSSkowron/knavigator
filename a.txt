**Cel Nadrzędny:** Wygeneruj pojedynczy, kompleksowy i gotowy do importu plik JSON dashboardu Grafana, zaprojektowany specjalnie do benchmarkowania i analizy wydajności oraz *alokacji zasobów* (nie rzeczywistego użycia!) harmonogramów Kubernetes (Kueue (z domyślnym kube-schedulerem), Volcano (custom-scheduler), YuniKorn (custom-scheduler)) w środowisku **symulowanym przez KWOK**. Dashboard musi efektywnie wizualizować wyniki dla opisanych scenariuszy benchmarkowych (V1, V2, V3 - opis poniżej), koncentrując się na dostarczeniu jak najpełniejszego obrazu dla **pojedynczego przebiegu testu**, ponieważ automatyczne porównywanie między testami za pomocą etykiet jest niemożliwe.

**Twoja rola:** Jesteś czołowym ekspertem w dziedzinie monitorowania systemów Kubernetes, specjalizującym się w batchowych i HPC workloadach oraz narzędziach do harmonogramowania (Kueue, Volcano, Apache YuniKorn). Masz głęboką wiedzę na temat metryk K8s (szczególnie `kube-state-metrics` i API Server), PromQL oraz projektowania zaawansowanych dashboardów Grafana. Kluczowe jest Twoje zrozumienie **ograniczeń i implikacji użycia KWOK** (brak metryk Kubelet/cAdvisor/node-exporter) oraz świadomość **braku etykietowania jobów/namespace'ów**. Musisz **proaktywnie** proponować metryki i wizualizacje, które maksymalizują wartość analityczną w tym specyficznym kontekście benchmarkowym **dla pojedynczego testu**. Oczekuję nie tylko wykonania, ale **eksperckiego wkładu** w projekt dashboardu.

**Kontekst Benchmarku:**
*   **Narzędzia:** Kueue, Volcano, YuniKorn (testowane sekwencyjnie, klaster usuwany między testami).
*   **Cel:** Analiza wydajności (przepustowość, czasy oczekiwania/wykonania) i efektywności *alokacji* zasobów (CPU, RAM, GPU) dla każdego testu indywidualnie. Porównanie między testami będzie musiało odbywać się manualnie (np. przez porównanie widoków z różnych zakresów czasowych).
*   **Środowisko:** Kubernetes z **węzłami roboczymi symulowanymi przez KWOK**.
*   **Kluczowe Ograniczenie:** **Joby ani Namespace'y używane do testów NIE są etykietowane** informacjami o typie scenariusza (V1/V2/V3), konfiguracji testu (np. 300j-300n) ani typie harmonogramu. To **uniemożliwia** automatyczne filtrowanie i porównywanie wyników między różnymi testami za pomocą dedykowanych zmiennych Grafana.

**Kluczowa Dyrektywa 1: Świadomość KWOK (ABSOLUTNIE KRYTYCZNE):**
*   **Ignoruj / Nie Używaj Metryk Węzła/Kontenera:** Zapomnij o metrykach z `node-exporter` (np. `node_cpu_seconds_total`, `node_memory_MemAvailable_bytes`) oraz `cAdvisor` (np. `container_cpu_usage_seconds_total`, `container_memory_working_set_bytes`) dla symulowanych węzłów KWOK. Te metryki będą **nieprawdziwe lub niedostępne**. Dashboard *nie może* na nich polegać.
*   **Skup się na Źródłach Danych KWOK-Kompatybilnych:**
    *   **`kube-state-metrics` (KSM):** Główne źródło informacji o stanie obiektów K8s (Pods, Nodes, Jobs, CRD harmonogramów etc.). Wykorzystaj metryki takie jak: `kube_pod_info`, `kube_pod_status_phase`, `kube_pod_status_scheduled_time`, `kube_pod_creation_timestamp`, `kube_pod_container_resource_requests`, `kube_pod_container_resource_limits`, `kube_node_status_allocatable`, `kube_node_spec_unschedulable`, `kube_job_status_succeeded`, `kube_job_status_failed`, `kube_job_spec_completions`, etc.
    *   **API Server (pośrednio przez KSM/Prometheus):** Stan obiektów, zdarzenia (Events - np. `FailedScheduling`).
    *   **Eksportery Harmonogramów (jeśli dostępne):** Zbadaj (na podstawie wiedzy eksperckiej lub dokumentacji), czy Kueue, Volcano, YuniKorn wystawiają własne metryki przez Prometheus endpoint (np. dotyczące stanu kolejek, decyzji harmonogramowania, liczby prób), które działają niezależnie od Kubeletów. Jeśli tak, wykorzystaj te, które są **ogólnie użyteczne** do analizy wydajności harmonogramu. Umieść je w dedykowanej, opcjonalnej sekcji.
*   **Metryki Muszą Odzwierciedlać *Stan* i *Alokację*, a Nie *Rzeczywiste Użycie*.**

**Kluczowa Dyrektywa 2: Obsługa Istniejących Dashboardów (Pliki JSON w Załączniku):**
*   **`knavigator - Kubernetes Pods Scheduling metrics` (grafana-config):** Traktuj jako **główny techniczny punkt odniesienia** dla poprawności zapytań KSM w środowisku KWOK. Zweryfikuj i użyj jako bazy dla podobnych metryk.
*   **Pozostałe Dashboardy (z 'NO DATA'):** Traktuj **wyłącznie jako źródło *pomysłów* na metryki i wizualizacje**. Zakładaj, że ich zapytania PromQL są **niepoprawne lub niekompatybilne z KWOK**. **NIE KOPIUJ** zapytań bezpośrednio. Jeśli identyfikujesz *koncepcyjnie* wartościowy panel, **zaprojektuj i zaimplementuj go od nowa**, używając poprawnych, KWOK-kompatybilnych metryk i zapytań PromQL.

**Kluczowa Dyrektywa 3: Analiza Scenariuszy Benchmarkowych (Opis Poniżej) - Adaptacja do Braku Etykiet:**
*   **Cel:** Opis scenariuszy V1, V2, V3 dostarcza kluczowego kontekstu dotyczącego charakteru obciążeń. Wykorzystaj tę wiedzę do **projektowania metryk i wizualizacji**, które będą wartościowe dla analizy *każdego typu scenariusza*, nawet jeśli nie można ich automatycznie filtrować.
*   **Brak Automatycznego Filtrowania wg Scenariusza/Konfiguracji:** Ponieważ brak jest etykiet `scenario_id`, `test_config`, `scheduler_type`, **NIE implementuj zmiennych Grafana opartych na tych etykietach do automatycznego filtrowania**. Dashboard nie będzie mógł dynamicznie przełączać widoków między scenariuszami/konfiguracjami/harmonogramami za pomocą dedykowanych zmiennych.
*   **Filtrowanie Manualne / Ograniczone:**
    *   **Zmienna `$namespace`:** Zaimplementuj zmienną `$namespace` (typu Query, np. `label_values(kube_namespace_status_phase{phase="Active"}, namespace)`), aby umożliwić filtrowanie danych, zakładając, że różne przebiegi testowe mogą być uruchamiane w różnych namespace'ach. To główny mechanizm grupowania danych dla pojedynczego testu/serii.
    *   **Poleganie na Zakresie Czasu:** Głównym sposobem porównywania wyników między różnymi testami (różne harmonogramy, różne konfiguracje V1/V2/V3) będzie **ręczne wybieranie odpowiednich zakresów czasowych** w Grafanie przez użytkownika. Projekt dashboardu musi to ułatwiać poprzez czytelność i spójność.
*   **Struktura Dashboardu:** Upewnij się, że główne sekcje (Wydajność, Alokacja Zasobów, Stan Podów/Jobów) zawierają wizualizacje i metryki, które są **istotne dla zrozumienia *każdego* z typów scenariuszy (V1, V2, V3)**, ponieważ nie będzie dedykowanej sekcji do filtrowania.

**Główne Zadanie: Stworzenie Ujednoliconego Dashboardu Grafana (JSON)**

**Kroki Implementacyjne dla Ciebie:**

1.  **Analiza i Weryfikacja:**
    *   Przeanalizuj *wszystkie* dostarczone informacje: ten prompt, opis scenariuszy (poniżej), skrypt tworzenia klastra (załącznik - zwróć uwagę na instalowane komponenty jak Prometheus, KSM, potencjalne eksportery), oraz *koncepcje* z załączonych plików JSON dashboardów. Zrozum ograniczenie braku etykiet.
    *   Skup się na identyfikacji metryk KSM/API/eksporterów, które są *ogólnie wartościowe* dla benchmarkowania harmonogramów, niezależnie od scenariusza.
    *   **Rygorystycznie Filtruj pod Kątem KWOK.** Odrzuć metryki node/cAdvisor. Zweryfikuj technicznie pozostałe (inspirując się `knavigator`).
    *   Zidentyfikuj luki w metrykach potrzebnych do pełnej analizy pojedynczego przebiegu testu dla różnych typów workloadów (V1/V2/V3).
    *   Dokumentuj odrzucone/przeformułowane metryki.

2.  **Projektowanie i Generowanie JSON:**
    *   **Struktura:** Zaprojektuj dashboard z logiczną strukturą, używając **Wierszy (Rows)** (np. "Przegląd Ogólny / Kluczowe Wskaźniki", "Wydajność Harmonogramowania", "Alokacja Zasobów (Żądania/Limity)", "Stan Podów i Jobów", "[Opcjonalnie] Metryki Specyficzne dla Harmonogramu").
    *   **Panele:** Stwórz panele wizualizujące *zweryfikowane, dostępne i wartościowe* metryki. Używaj różnorodnych typów wizualizacji (Time series, Stat, Gauge, Bar chart, Histogram, Table). **Dodaj jasne opisy** do każdego panelu, wyjaśniając metrykę i jej znaczenie w kontekście KWOK oraz potencjalnych scenariuszy. Upewnij się, że panele są użyteczne dla analizy V1, V2 i V3.
    *   **Zapytania PromQL:** Wygeneruj **precyzyjne i poprawne zapytania PromQL**, bazujące głównie na KSM, które będą działać w środowisku KWOK i odpowiadać potrzebom wizualizacji. Wykorzystaj zmienną `$namespace` do filtrowania. Pamiętaj o odpowiednich agregacjach i funkcjach (`rate`, `increase`, `sum`, `avg`, `quantile`, `histogram_quantile`, `label_join` etc.).
    *   **Zmienne (Variables):** Zaimplementuj `$datasource` (standardowo) i `$namespace`. **NIE implementuj zmiennych opartych na nieistniejących etykietach scenariusza/konfiguracji/harmonogramu.**
    *   **Porównywalność (Wizualna/Manualna):** Zadbaj o spójne nazewnictwo, jednostki (np. sekundy, rdzenie, bajty GiB) i w miarę możliwości stałe skale osi Y, aby ułatwić *manualne* porównywanie widoków z różnych testów (różnych zakresów czasowych).
    *   **Proaktywne Ulepszenia (Kluczowy Wkład Ekspercki):**
        *   **Dodaj Metryki/Wizualizacje:** Zaproponuj i zaimplementuj dodatkowe panele wykraczające poza minimum i inspiracje, np.:
            *   Rozkład/Histogram czasu oczekiwania podów w stanie `Pending` (`kube_pod_status_scheduled_time` - `kube_pod_creation_timestamp`).
            *   Wizualizacja "ciśnienia" na zasoby: `sum(kube_pod_container_resource_requests{resource="cpu", namespace="$namespace"})` / `sum(kube_node_status_allocatable{resource="cpu"})` (i podobnie dla RAM/GPU).
            *   Wskaźnik fragmentacji *alokacji* (przybliżony): np. liczba węzłów z małymi ilościami alokowalnych zasobów pozostałych (trudne, ale może jakiś wskaźnik oparty na KSM?).
            *   Liczba błędów `FailedScheduling` (z K8s Events, jeśli Prometheus je zbiera - wymaga odpowiedniej konfiguracji Prometheus).
            *   Panele pokazujące rozkład wielkości żądań zasobów (CPU/RAM/GPU) dla podów w stanie Pending/Running.
        *   **Uzasadnij:** W podsumowaniu wyjaśnij *dlaczego* te dodatkowe elementy są wartościowe dla celu benchmarkowania w kontekście KWOK i analizy różnych typów scenariuszy (V1/V2/V3), nawet bez automatycznego filtrowania.

**Minimalny Zestaw Wymaganych Widoków/Metryk (KWOK-Aware, bez filtrowania wg scenariuszy):**

*   **[ROW] Przegląd Ogólny / Kluczowe Wskaźniki (dla wybranego `$namespace`/zakresu czasu):**
    *   Aktualna liczba jobów/podów w stanie Pending(oraz suspended dla Kueue)/Running/Succeeded/Failed (Gauge/Stat, z KSM, filtrowane przez `$namespace`).
    *   Całkowite żądane vs. alokowalne zasoby CPU/RAM/GPU w klastrze (Gauge/Stat, żądane filtrowane przez `$namespace`).
    *   Średnia/P95 przepustowość harmonogramowania podów (Stat/TimeSeries, `rate(kube_pod_status_scheduled_time{condition="true", namespace="$namespace"}...))`.
*   **[ROW] Wydajność Harmonogramowania:**
    *   Przepustowość harmonogramowania podów (Liczba podów/s które obsługuje harmonogram) (TimeSeries, filtrowane przez `$namespace`).
    *   Czas oczekiwania Poda (`Pending` duration): Czas od `kube_pod_creation_timestamp` do `kube_pod_status_scheduled_time`. (Avg, P95, P99, Histogram/Rozkład, filtrowane przez `$namespace`). Warto się tutaj zastanowić dla przypadku narzędzia Kueue w którym Joby są suspended przed przekazaniem ich przez Kueue do `kube-schedulera`.
    *   Czas "wykonywania" Joba (bazując na KSM): Czas od pierwszego Poda Joba w `Running` (lub `Scheduled`) do ostatniego Poda Joba w `Succeeded`/`Failed`. (Avg, P95, P99, Histogram/Rozkład, filtrowane przez `$namespace`). **Dodaj notatkę o symulacji KWOK.**
    *   Całkowity czas Joba: Od `kube_job_creation_timestamp` do `kube_job_status_completion_time`. (Avg, P95, P99, Histogram/Rozkład, filtrowane przez `$namespace`).
    *   Liczba błędów harmonogramowania (`FailedScheduling` Events lub `kube_pod_status_phase{phase="Failed", namespace="$namespace"}` z odpowiednim powodem, jeśli dostępny).
*   **[ROW] Alokacja Zasobów (Żądania/Limity - NIE UŻYCIE):**
    *   Żądane vs. Alokowalne zasoby (CPU, RAM, GPU) w klastrze w czasie (TimeSeries, Stacked Graph, żądane filtrowane przez `$namespace`).
    *   Liczba podów alokowanych per węzeł (bazując na `kube_pod_info{namespace="$namespace"}` i polu `node`) (Heatmap/Table/Bar Chart).
    *   Żądane zasoby (CPU, RAM, GPU) per węzeł (Heatmap/Table/Bar Chart, sumując pody z `$namespace`).
    *   *Potencjalny* wskaźnik fragmentacji alokacji (np. histogram alokowalnych zasobów per węzeł).
*   **[ROW] Stan Podów i Jobów:**
    *   Liczba Podów w fazach `Pending`, `Running`, `Succeeded`, `Failed` w czasie (TimeSeries, Stacked, filtrowane przez `$namespace`).
    *   Liczba Jobów w stanie `Active`, `Succeeded`, `Failed` w czasie (TimeSeries, Stacked, filtrowane przez `$namespace`).
    *   Tabela z Jobami, które zakończyły się niepowodzeniem (filtrowane przez `$namespace`).
*   **[ROW - Opcjonalny] Metryki Specyficzne dla Harmonogramu:**
    *   Panele wykorzystujące metryki z dedykowanych eksporterów Kueue/Volcano/YuniKorn, jeśli zostały zidentyfikowane jako dostępne i użyteczne. Powinny również respektować filtr `$namespace`.

**Dane Wejściowe:**

1.  **Opis Scenariuszy Benchmarkowych:**
    ```
    ## Wydajność i Skalowalność (Performance & Scalability)

    Benchmarki wydajności dostarczają kompleksowej oceny framework'ów schedulerów w różnych wzorcach obciążeń, mierząc przepustowość, skalowalność i efektywność wykorzystania zasobów. Testy te symulują różne scenariusze, które mogą wystąpić w rzeczywistych środowiskach produkcyjnych.

    ### V1: Duża liczba identycznych, niezależnych jobów

    Benchmark testuje zdolność schedulera do obsługi dużej liczby identycznych, niezależnych zadań. Mierzy wydajność i skalowalność schedulera i efektywność w obsłudze wielu małych zadań.

    #### Konfiguracje

    Benchmark zawiera wiele konfiguracji z różnymi kombinacjami liczby węzłów i zadań:

    ##### Liczba jobów: 300

    - **300 węzłów**: Test 300 jobów na 300 węzłach
    - **400 węzłów**: Test 300 jobów na 400 węzłach
    - **500 węzłów**: Test 300 jobów na 500 węzłach

    ##### Liczba jobów: 400

    - **300 węzłów**: Test 400 jobów na 300 węzłach
    - **400 węzłów**: Test 400 jobów na 400 węzłach
    - **500 węzłów**: Test 400 jobów na 500 węzłach

    ##### Liczba jobów: 500

    - **300 węzłów**: Test 500 jobów na 300 węzłach
    - **400 węzłów**: Test 500 jobów na 400 węzłach
    - **500 węzłów**: Test 500 jobów na 500 węzłach

    Każda konfiguracja testu wykorzystuje:

    - Wirtualne węzły, każdy z 128 rdzeniami CPU, 1Ti pamięci i 8 GPU
    - Niezależne joby, gdzie każdy składa się z pojedynczego poda o wymaganiach:
    - 16 rdzeni CPU (12,5% węzła)
    - 256Gi pamięci (25% węzła)
    - 4 GPU (50% węzła)

    Wykorzystanie zasobów klastra różni się w zależności od konfiguracji:

    | Konfiguracja | Wykorzystanie CPU | Wykorzystanie pamięci | Wykorzystanie GPU |
    |---------------|-----------|-------------|-----------|
    | 300 jobów, 300 węzłów | 12,5% | 25% | 50% |
    | 300 jobów, 400 węzłów | 9,38% | 18,75% | 37,5% |
    | 300 jobów, 500 węzłów | 7,5% | 15% | 30% |
    | 400 jobów, 300 węzłów | 16,67% | 33,33% | 66,67% |
    | 400 jobów, 400 węzłów | 12,5% | 25% | 50% |
    | 400 jobów, 500 węzłów | 10% | 20% | 40% |
    | 500 jobów, 300 węzłów | 20,83% | 41,67% | 83,33% |
    | 500 jobów, 400 węzłów | 15,63% | 31,25% | 62,5% |
    | 500 jobów, 500 węzłów | 12,5% | 25% | 50% |

    ### V2: Jeden duży wielopodowy job

    Benchmark testuje efektywność schedulera w obsłudze zadań składających się z wielu podów. Ocenia, jak dobrze scheduler radzi sobie z dużym, spójnym obciążeniem.

    #### Konfiguracje

    Benchmark zawiera wiele konfiguracji z różnymi kombinacjami liczby węzłów i podów w zadaniu:

    ##### Liczba replik: 300

    - **300 węzłów**: Test 1 joba z 300 replikami na 300 węzłach
    - **400 węzłów**: Test 1 joba z 300 replikami na 400 węzłach
    - **500 węzłów**: Test 1 joba z 300 replikami na 500 węzłach

    ##### Liczba replik: 400

    - **300 węzłów**: Test 1 joba z 400 replikami na 300 węzłach
    - **400 węzłów**: Test 1 joba z 400 replikami na 400 węzłach
    - **500 węzłów**: Test 1 joba z 400 replikami na 500 węzłach

    ##### Liczba replik: 500

    - **300 węzłów**: Test 1 joba z 500 replikami na 300 węzłach
    - **400 węzłów**: Test 1 joba z 500 replikami na 400 węzłach
    - **500 węzłów**: Test 1 joba z 500 replikami na 500 węzłach

    Każda konfiguracja testu wykorzystuje:

    - Wirtualne węzły, każdy z 128 rdzeniami CPU, 1Ti pamięci i 8 GPU
    - Jeden wielopodowy job, gdzie każdy pod ma wymagania:
    - 16 rdzeni CPU (12,5% węzła)
    - 256Gi pamięci (25% węzła)
    - 4 GPU (50% węzła)

    Wykorzystanie zasobów klastra różni się w zależności od konfiguracji:

    | Konfiguracja | Wykorzystanie CPU | Wykorzystanie pamięci | Wykorzystanie GPU |
    |---------------|-----------|-------------|-----------|
    | 300 replik, 300 węzłów | 12,5% | 25% | 50% |
    | 300 replik, 400 węzłów | 9,38% | 18,75% | 37,5% |
    | 300 replik, 500 węzłów | 7,5% | 15% | 30% |
    | 400 replik, 300 węzłów | 16,67% | 33,33% | 66,67% |
    | 400 replik, 400 węzłów | 12,5% | 25% | 50% |
    | 400 replik, 500 węzłów | 10% | 20% | 40% |
    | 500 replik, 300 węzłów | 20,83% | 41,67% | 83,33% |
    | 500 replik, 400 węzłów | 15,63% | 31,25% | 62,5% |
    | 500 replik, 500 węzłów | 12,5% | 25% | 50% |

    ### V3: Mieszane stopniowe obciążenie

    Benchmark testuje wydajność schedulera z różnorodnymi obciążeniami, które lepiej reprezentują rzeczywiste wzorce użytkowania klastra. Ocenia, jak dobrze scheduler radzi sobie z heterogenicznymi typami zadań o różnych wymaganiach zasobowych jednocześnie.

    #### Konfiguracje

    Benchmark zawiera wiele konfiguracji z różnymi kombinacjami liczby węzłów i liczby zadań:

    ##### Liczba zadań każdego typu: 100 (łącznie 300 zadań)

    - **300 węzłów**: Test z 300 węzłami i 100 zadaniami każdego typu
    - **400 węzłów**: Test z 400 węzłami i 100 zadaniami każdego typu
    - **500 węzłów**: Test z 500 węzłami i 100 zadaniami każdego typu

    ##### Liczba zadań każdego typu: 200 (łącznie 600 zadań)

    - **300 węzłów**: Test z 300 węzłami i 200 zadaniami każdego typu
    - **400 węzłów**: Test z 400 węzłami i 200 zadaniami każdego typu
    - **500 węzłów**: Test z 500 węzłami i 200 zadaniami każdego typu

    ##### Liczba zadań każdego typu: 300 (łącznie 900 zadań)

    - **300 węzłów**: Test z 300 węzłami i 300 zadaniami każdego typu
    - **400 węzłów**: Test z 400 węzłami i 300 zadaniami każdego typu
    - **500 węzłów**: Test z 500 węzłami i 300 zadaniami każdego typu

    Każda konfiguracja testu wykorzystuje:

    - Wirtualne węzły, każdy z 128 rdzeniami CPU, 1Ti pamięci i 8 GPU
    - Trzy różne typy zadań uruchamiane równolegle:

    - **Zadania o wysokim użyciu GPU**: Zadania wykorzystujące całe węzły GPU (8 GPU na job)

        - 16 rdzeni CPU (12.5% węzła)
        - 96Gi pamięci (9.4% węzła)
        - 8 GPU (100% węzła)

    - **Zadania o średnim użyciu GPU**: Zadania z częściowym wykorzystaniem GPU (2 GPU na job)

        - 8 rdzeni CPU (6.25% węzła)
        - 32Gi pamięci (3.1% węzła)
        - 2 GPU (25% węzła)

    - **Zadania CPU-only**: Zadania bez wymagań GPU

        - 32 rdzenie CPU (25% węzła)
        - 128Gi pamięci (12.5% węzła)
        - 0 GPU

    Wykorzystanie zasobów klastra różni się w zależności od konfiguracji:

    | Konfiguracja węzłów | Liczba zadań | Całkowite wykorzystanie CPU | Całkowite wykorzystanie pamięci | Całkowite wykorzystanie GPU |
    |-----------|-----------|-----------|-----------|-----------|
    | 300 | 100 każdego typu | 14,58% | 8,33% | 41,67% |
    | 300 | 200 każdego typu | 29,17% | 16,67% | 83,33% |
    | 300 | 300 każdego typu | 43,75% | 25,00% | 125,00% |
    | 400 | 100 każdego typu | 10,94% | 6,25% | 31,25% |
    | 400 | 200 każdego typu | 21,88% | 12,50% | 62,50% |
    | 400 | 300 każdego typu | 32,81% | 18,75% | 93,75% |
    | 500 | 100 każdego typu | 8,75% | 5,00% | 25,00% |
    | 500 | 200 każdego typu | 17,50% | 10,00% | 50,00% |
    | 500 | 300 każdego typu | 26,25% | 15,00% | 75,00% |

2.  **Pliki JSON z Istniejącymi Dashboardami:** Dołączone jako osobne pliki/załączniki.
3.  **Skrypt Tworzenia Środowiska Testowego:** Dołączony jako osobny plik/załącznik.

**Format Wyjściowy:**

1.  **Podsumowanie (Przed JSON):**
    *   Kluczowe decyzje projektowe (np. wybór metryk KSM, struktura Rows, implementacja zmiennych `$namespace`).
    *   Wylistowanie napotkanych problemów z porównywalnością metryk (wynikających z KWOK lub specyfiki narzędzi) i jak sobie z nimi poradzono.
    *   **Wyraźna notatka o ograniczeniu wynikającym z braku etykiet na jobach/namespace'ach:** Podkreślenie, że dashboard jest zoptymalizowany pod kątem analizy pojedynczego przebiegu testu i że porównywanie między różnymi testami (scenariusze, konfiguracje, harmonogramy) wymaga **manualnego wyboru zakresu czasowego** i/lub filtrowania przez `$namespace`.
    *   Informacje o tym, jak poradzono sobie z potencjalnie błędnymi zapytaniami z dashboardów 'NO DATA' (odrzucenie/modyfikacja).
    *   **Lista i zwięzłe uzasadnienie dla WSZYSTKICH dodanych/zaproponowanych przez Ciebie (jako eksperta) metryk, wizualizacji lub zmiennych**, które wykraczają poza minimum lub inspiracje z plików wejściowych, **łącząc je z potrzebami analizy różnych typów scenariuszy (V1/V2/V3) w ramach pojedynczego testu**.
    *   Wyjaśnienie zaimplementowanych zmiennych (`$namespace`).
2.  **Pojedynczy Plik JSON:** Kompletny, poprawny składniowo i gotowy do importu w Grafanie JSON dashboardu.
