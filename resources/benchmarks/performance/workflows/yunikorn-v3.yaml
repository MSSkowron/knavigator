name: yunikorn-performance-benchmark-v3
description: |
  Performance benchmark for YuniKorn with diverse workloads.
  This tests the scheduler's ability to handle heterogeneous job types
  with different resource requirements simultaneously.
tasks:
  # Configure nodes
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 700
          labels:
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: 128
            memory: "1Ti"
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Configure YuniKorn
  - id: configure-yunikorn
    type: Configure
    params:
      configmaps:
        - name: yunikorn-configs
          namespace: yunikorn
          op: create
          data:
            queues.yaml: |
              partitions:
                - name: default
                  queues:
                  - name: root
                    queues:
                    - name: perf-benchmark
                      submitacl: '*'
                      resources:
                        guaranteed:
                          memory: 10Gi
                          vcore: 10000m
                          nvidia.com/gpu: 100
                        max:
                          memory: 700Ti
                          vcore: 89600000m     # 128 cores × 700 nodes
                          nvidia.com/gpu: 5600 # 8 GPUs × 700 nodes
            # Performance-optimized settings
            yunikorn-defaults.yaml: |
              serviceCacheMaxJitter: 0
              batchMaxJitterPercent: 0
              enableForcefulNodeRemoval: true
              cacheMetricsEnabled: true
      deploymentRestarts:
        - namespace: yunikorn
          name: yunikorn-scheduler
      timeout: 5m

  # Register job templates for different types
  - id: register-high-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "high-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.parallelism}}"

  - id: register-medium-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "medium-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.parallelism}}"

  - id: register-cpu-only
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "cpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.parallelism}}"

  # Warmup phase - submit a few small jobs to initialize system
  - id: warmup-batch
    type: SubmitObj
    params:
      refTaskId: register-high-gpu
      count: 5
      params:
        namespace: default
        completions: 1
        parallelism: 1
        applicationId: "warmup"
        queue: "root.perf-benchmark"
        image: ubuntu
        cpu: 100m
        memory: 128M
        gpu: 1
        ttl: 5s

  # Short delay after warmup
  - id: warmup-delay
    type: Sleep
    params:
      timeout: 15s

  # Group 1: High-GPU Jobs (8 GPUs per job)
  # Total resources:
  # - 4,800 CPU cores (300 × 16 = 5.36% of cluster)
  # - ~28.1Ti memory (300 × 96Gi = 4.02% of cluster)
  # - 2,400 GPUs (300 × 8 = 42.86% of cluster)
  - id: high-gpu-jobs
    type: SubmitObj
    params:
      refTaskId: register-high-gpu
      count: 300
      params:
        namespace: default
        completions: 1
        parallelism: 1
        applicationId: "high-gpu"
        queue: "root.perf-benchmark"
        image: ubuntu
        cpu: 16000m # 16 cores (12.5% of node)
        memory: 96Gi # 96GB (9.4% of node)
        gpu: 8 # 8 GPUs (100% of node)
        ttl: 5m

  # Group 2: Medium-GPU Jobs (2 GPUs per job)
  # Total resources:
  # - 1,600 CPU cores (200 × 8 = 1.79% of cluster)
  # - ~6.25Ti memory (200 × 32Gi = 0.89% of cluster)
  # - 400 GPUs (200 × 2 = 7.14% of cluster)
  - id: medium-gpu-jobs
    type: SubmitObj
    params:
      refTaskId: register-medium-gpu
      count: 200
      params:
        namespace: default
        completions: 1
        parallelism: 1
        applicationId: "medium-gpu"
        queue: "root.perf-benchmark"
        image: ubuntu
        cpu: 8000m # 8 cores (6.25% of node)
        memory: 32Gi # 32GB (3.1% of node)
        gpu: 2 # 2 GPUs (25% of node)
        ttl: 5m

  # Group 3: CPU-Only Jobs (no GPUs)
  # Total resources:
  # - 6,400 CPU cores (200 × 32 = 7.14% of cluster)
  # - ~25Ti memory (200 × 128Gi = 3.57% of cluster)
  # - 0 GPUs
  - id: cpu-only-jobs
    type: SubmitObj
    params:
      refTaskId: register-cpu-only
      count: 200
      params:
        namespace: default
        completions: 1
        parallelism: 1
        applicationId: "cpu-only"
        queue: "root.perf-benchmark"
        image: ubuntu
        cpu: 32000m # 32 cores (25% of node)
        memory: 128Gi # 128GB (12.5% of node)
        gpu: 0 # No GPUs
        ttl: 5m

  # Analysis phase - time to collect metrics
  - id: analysis-phase
    type: Sleep
    params:
      timeout: 60s
# Total cluster utilization:
# - 12,800 CPU cores (14.3% of cluster)
# - ~59.4Ti memory (8.5% of cluster)
# - 2,800 GPUs (50% of cluster)
