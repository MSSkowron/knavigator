# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: enhanced-yunikorn-benchmark
description: |
  A comprehensive performance benchmark for YuniKorn scheduler testing that:
  1. Collects baseline metrics before testing
  2. Performs incremental scaling tests to identify performance limits
  3. Measures key performance indicators like throughput and scheduling latency
  4. Tests resource utilization efficiency under varied conditions
tasks:
# Configure nodes and YuniKorn settings
- id: configure
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 700
      labels:
        nvidia.com/gpu.count: "8"
    namespaces:
    - name: perf-benchmark
      op: create
    configmaps:
    - name: benchmark-metrics
      namespace: perf-benchmark
      op: create
      data:
        start_time: ""
        test_phase: "setup"
        pods_scheduled: "0"
        pods_pending: "0"
        scheduler_cpu_usage: "0"
        scheduler_memory_usage: "0"
    - name: yunikorn-configs
      namespace: yunikorn
      op: create
      data:
        queues.yaml: |
          partitions:
            - name: default
              queues:
              - name: root
                queues:
                - name: perf-benchmark
                  submitacl: '*'
                  resources:
                    guaranteed:
                      memory: 10Gi
                      vcore: 10000m
                      nvidia.com/gpu: 100
                    max:
                      memory: 700Gi
                      vcore: 70000m
                      nvidia.com/gpu: 5600
        # Performance-optimized settings
        yunikorn-defaults.yaml: |
          serviceCacheMaxJitter: 0
          batchMaxJitterPercent: 0
          enableForcefulNodeRemoval: true
          cacheMetricsEnabled: true
    deploymentRestarts:
    - namespace: yunikorn
      name: yunikorn-scheduler
    timeout: 5m

# Register YuniKorn-specific resources
- id: register-job
  type: RegisterObj
  params:
    template: "resources/templates/yunikorn/job.yml"
    nameFormat: "perftest-job{{._ENUM_}}"
    podNameFormat: "{{._NAME_}}-.*"
    podCount: "{{.parallelism}}"
- id: register-configmap
  type: RegisterObj
  params:
    template: "resources/templates/k8s/configmap.yaml"

# Create metrics ConfigMap
- id: create-metrics-configmap
  type: SubmitObj
  params:
    refTaskId: register-configmap
    count: 1
    params:
      namespace: perf-benchmark
      name: metrics-tracking
      data:
        test_phase: "setup"
        start_time: ""

# Record baseline metrics
- id: update-test-phase-baseline
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "baseline"
        start_time: "{{now}}"
    timeout: 5s

# Small scale test - 50 pods
- id: update-test-phase-small
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "small_scale"
        start_time: "{{now}}"
    timeout: 5s

- id: small-scale-test
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 50
    params:
      namespace: perf-benchmark
      parallelism: 1
      completions: 1
      applicationId: "perf-small-scale"
      queue: "root.perf-benchmark"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 1
      ttl: "30s"

- id: small-scale-wait
  type: CheckPod
  params:
    refTaskId: small-scale-test
    status: Running
    timeout: 2m

- id: update-small-scale-metrics
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        small_scale_completion_time: "{{now}}"
        small_scale_status: "completed"
    timeout: 5s

# Medium scale test - 200 pods
- id: update-test-phase-medium
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "medium_scale"
        start_time: "{{now}}"
    timeout: 5s

- id: medium-scale-test
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 4
    params:
      namespace: perf-benchmark
      parallelism: 50
      completions: 50
      applicationId: "perf-medium-scale"
      queue: "root.perf-benchmark"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 1
      ttl: "30s"

- id: medium-scale-wait
  type: CheckPod
  params:
    refTaskId: medium-scale-test
    status: Running
    timeout: 5m

- id: update-medium-scale-metrics
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        medium_scale_completion_time: "{{now}}"
        medium_scale_status: "completed"
    timeout: 5s

# Large scale test - 700 pods
- id: update-test-phase-large
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "large_scale"
        start_time: "{{now}}"
    timeout: 5s

- id: large-scale-test
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: perf-benchmark
      parallelism: 700
      completions: 700
      applicationId: "perf-large-scale"
      queue: "root.perf-benchmark"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 1
      ttl: "60s"

- id: large-scale-wait
  type: CheckPod
  params:
    refTaskId: large-scale-test
    status: Running
    timeout: 10m

- id: update-large-scale-metrics
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        large_scale_completion_time: "{{now}}"
        large_scale_status: "completed"
    timeout: 5s

# Burst test - rapid submission of many jobs
- id: update-test-phase-burst
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "burst_test"
        start_time: "{{now}}"
    timeout: 5s

- id: clear-previous-jobs
  type: DeleteObj
  params:
    refTaskId: large-scale-test

- id: burst-test
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 100
    params:
      namespace: perf-benchmark
      parallelism: 5
      completions: 5
      applicationId: "perf-burst-test"
      queue: "root.perf-benchmark"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 1
      ttl: "30s"

- id: burst-test-wait
  type: CheckPod
  params:
    refTaskId: burst-test
    status: Running
    timeout: 10m

- id: update-burst-test-metrics
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        burst_test_completion_time: "{{now}}"
        burst_test_status: "completed"
    timeout: 5s

# Generate final report
- id: benchmark-summary
  type: UpdateObj
  params:
    refTaskId: create-metrics-configmap
    state:
      data:
        test_phase: "completed"
        completion_time: "{{now}}"
    timeout: 5s

- id: check-final-metrics
  type: CheckConfigmap
  params:
    name: metrics-tracking
    namespace: perf-benchmark
    op: subset
    data:
      test_phase: "completed"