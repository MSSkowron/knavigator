name: kueue-performance-benchmark-v3-400-300
description: |
  Kompleksowy benchmark dla testowania wydajności Kueue z wykorzystaniem zróżnicowanych
  obciążeń, symulujących rzeczywiste scenariusze produkcyjne. Test obejmuje zadania
  wykorzystujące całe węzły GPU, częściowe węzły oraz zadania wyłącznie CPU/pamięć.
  Pozwala to na ocenę zarówno przepustowości harmonogramowania, jak i efektywności
  bin-packingu (upakowania) zasobów.
tasks:
  # Configure nodes
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 400
          labels:
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: 128100m
            memory: 1048626Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Configure Kueue
  - id: configure-kueue
    type: Configure
    params:
      configmaps:
        - name: kueue-manager-config
          namespace: kueue-system
          op: create
          data:
            controller_manager_config.yaml: |
              apiVersion: config.kueue.x-k8s.io/v1beta1
              kind: Configuration
              health:
                healthProbeBindAddress: :8081
              metrics:
                bindAddress: :8080
                enableClusterQueueResources: true
              webhook:
                port: 9443
              leaderElection:
                leaderElect: true
                resourceName: c1f6bfd2.kueue.x-k8s.io
              controller:
                groupKindConcurrency:
                  Job.batch: 5
                  Pod: 5
                  Workload.kueue.x-k8s.io: 5
                  LocalQueue.kueue.x-k8s.io: 1
                  ClusterQueue.kueue.x-k8s.io: 1
                  ResourceFlavor.kueue.x-k8s.io: 1
              clientConnection:
                qps: 50
                burst: 100
              #pprofBindAddress: :8083
              waitForPodsReady:
                enable: true
                timeout: 5m
                blockAdmission: true
                requeuingStrategy:
                  timestamp: Eviction
                  backoffLimitCount: null
                  backoffBaseSeconds: 60
                  backoffMaxSeconds: 3600
              #manageJobsWithoutQueueName: true
              #internalCertManagement:
              #  enable: false
              #  webhookServiceName: ""
              #  webhookSecretName: ""
              integrations:
                frameworks:
                - "batch/job"
                - "kubeflow.org/mpijob"
                - "ray.io/rayjob"
                - "ray.io/raycluster"
                - "jobset.x-k8s.io/jobset"
                - "kubeflow.org/paddlejob"
                - "kubeflow.org/pytorchjob"
                - "kubeflow.org/tfjob"
                - "kubeflow.org/xgboostjob"
              #  - "pod"
              #  externalFrameworks:
              #  - "Foo.v1.example.com"
                podOptions:
                  namespaceSelector:
                    matchExpressions:
                      - key: kubernetes.io/metadata.name
                        operator: NotIn
                        values: [ kube-system, kueue-system ]
              #fairSharing:
              #  enable: true
              #  preemptionStrategies: [LessThanOrEqualToFinalShare, LessThanInitialShare]
              #resources:
              #  excludeResourcePrefixes: []
      deploymentRestarts:
        - namespace: kueue-system
          name: kueue-controller-manager
      timeout: 10m

  - id: config-sleep
    type: Sleep
    params:
      timeout: 5s

  # Register Kueue queue resources
  - id: register-cluster-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/cluster-queue.yaml"
  - id: register-local-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/local-queue.yaml"
  - id: register-resource-flavor
    type: RegisterObj
    params:
      template: "resources/templates/kueue/resource-flavor.yaml"

  # Register templates for different job types
  - id: register-job-warmup
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "warmup-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-high-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "high-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-medium-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "medium-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-cpu-only
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "cpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  # Create resource flavor and queues
  - id: create-resource-flavor
    type: SubmitObj
    params:
      refTaskId: register-resource-flavor
      canExist: true
      params:
        name: "gpu-node"
        nodeLabels:
          nvidia.com/gpu.count: "8"

  - id: create-cluster-queue
    type: SubmitObj
    params:
      refTaskId: register-cluster-queue
      canExist: true
      params:
        name: team
        flavor: gpu-node
        cpu: 51200 # 400 węzłów × 128 rdzeni
        memory: 400Ti # 400 węzłów × 1Ti
        pods: 44000 # 400 węzłów × 110 podów
        gpu: 3200 # 400 węzłów × 8 GPU

  - id: create-local-queue
    type: SubmitObj
    params:
      refTaskId: register-local-queue
      canExist: true
      params:
        name: team-queue
        namespace: default
        clusterQueue: team

  # --- Submit All Job Groups Simultaneously using Parallel Task ---
  - id: submit-all-jobs-parallel
    type: Parallel
    params:
      tasks:
        # Group 1: High-GPU Jobs (8 GPUs per job)
        - type: SubmitObj
          params:
            refTaskId: register-job-high-gpu
            count: 300
            params:
              namespace: default
              replicas: 1
              completionMode: NonIndexed
              queueName: team-queue
              cpu: 16000m # 16 rdzeni (12.5% węzła)
              memory: 96Gi # 96GB (9.4% węzła)
              gpu: 8 # 8 GPU (100% węzła)
              ttl: 5m

        # Group 2: Medium-GPU Jobs (2 GPUs per job)
        - type: SubmitObj
          params:
            refTaskId: register-job-medium-gpu
            count: 300
            params:
              namespace: default
              replicas: 1
              completionMode: NonIndexed
              queueName: team-queue
              cpu: 8000m # 8 rdzeni (6.25% węzła)
              memory: 32Gi # 32GB (3.1% węzła)
              gpu: 2 # 2 GPU (25% węzła)
              ttl: 5m

        # Group 3: CPU-Only Jobs (no GPUs)
        - type: SubmitObj
          params:
            refTaskId: register-job-cpu-only
            count: 300
            params:
              namespace: default
              replicas: 1
              completionMode: NonIndexed
              queueName: team-queue
              cpu: 32000m # 32 rdzenie (25% węzła)
              memory: 128Gi # 128GB (12.5% węzła)
              gpu: 0 # Bez GPU
              ttl: 5m
# Total cluster utilization:
# - 16,800 CPU cores (32.81% of cluster)
# - ~75Ti memory (18.75% of cluster)
# - 3,000 GPUs (93.75% of cluster)
