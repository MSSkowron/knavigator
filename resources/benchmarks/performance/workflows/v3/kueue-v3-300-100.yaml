name: kueue-performance-benchmark-v3-300-100
description: |
  Kompleksowy benchmark dla testowania wydajności Kueue z wykorzystaniem zróżnicowanych
  obciążeń, symulujących rzeczywiste scenariusze produkcyjne. Test obejmuje zadania
  wykorzystujące całe węzły GPU, częściowe węzły oraz zadania wyłącznie CPU/pamięć.
  Pozwala to na ocenę zarówno przepustowości harmonogramowania, jak i efektywności
  bin-packingu (upakowania) zasobów.
tasks:
  # Configure nodes
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 300
          labels:
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: 128100m
            memory: 1048626Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Configure Kueue
  - id: configure-kueue
    type: Configure
    params:
      configmaps:
        - name: kueue-manager-config
          namespace: kueue-system
          op: create
          data:
            controller_manager_config.yaml: |
              apiVersion: config.kueue.x-k8s.io/v1beta1
              kind: Configuration
              health:
                healthProbeBindAddress: :8081
              metrics:
                bindAddress: :8080
                enableClusterQueueResources: true
              webhook:
                port: 9443
              leaderElection:
                leaderElect: true
                resourceName: c1f6bfd2.kueue.x-k8s.io
              controller:
                groupKindConcurrency:
                  Job.batch: 5
                  Pod: 5
                  Workload.kueue.x-k8s.io: 5
                  LocalQueue.kueue.x-k8s.io: 1
                  ClusterQueue.kueue.x-k8s.io: 1
                  ResourceFlavor.kueue.x-k8s.io: 1
              clientConnection:
                qps: 50
                burst: 100
              #pprofBindAddress: :8083
              waitForPodsReady:
                enable: true
                timeout: 5m
                blockAdmission: true
                requeuingStrategy:
                  timestamp: Eviction
                  backoffLimitCount: null
                  backoffBaseSeconds: 60
                  backoffMaxSeconds: 3600
              #manageJobsWithoutQueueName: true
              #internalCertManagement:
              #  enable: false
              #  webhookServiceName: ""
              #  webhookSecretName: ""
              integrations:
                frameworks:
                - "batch/job"
                - "kubeflow.org/mpijob"
                - "ray.io/rayjob"
                - "ray.io/raycluster"
                - "jobset.x-k8s.io/jobset"
                - "kubeflow.org/paddlejob"
                - "kubeflow.org/pytorchjob"
                - "kubeflow.org/tfjob"
                - "kubeflow.org/xgboostjob"
              #  - "pod"
              #  externalFrameworks:
              #  - "Foo.v1.example.com"
                podOptions:
                  namespaceSelector:
                    matchExpressions:
                      - key: kubernetes.io/metadata.name
                        operator: NotIn
                        values: [ kube-system, kueue-system ]
              #fairSharing:
              #  enable: true
              #  preemptionStrategies: [LessThanOrEqualToFinalShare, LessThanInitialShare]
              #resources:
              #  excludeResourcePrefixes: []
      deploymentRestarts:
        - namespace: kueue-system
          name: kueue-controller-manager
      timeout: 10m

  - id: config-sleep
    type: Sleep
    params:
      timeout: 5s

  # Register Kueue queue resources
  - id: register-cluster-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/cluster-queue.yaml"
  - id: register-local-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/local-queue.yaml"
  - id: register-resource-flavor
    type: RegisterObj
    params:
      template: "resources/templates/kueue/resource-flavor.yaml"

  # Register templates for different job types
  - id: register-job-warmup
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "warmup-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-high-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "high-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-medium-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "medium-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  - id: register-job-cpu-only
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "cpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.replicas}}"

  # Create resource flavor and queues
  - id: create-resource-flavor
    type: SubmitObj
    params:
      refTaskId: register-resource-flavor
      canExist: true
      params:
        name: "gpu-node"
        nodeLabels:
          nvidia.com/gpu.count: "8"

  - id: create-cluster-queue
    type: SubmitObj
    params:
      refTaskId: register-cluster-queue
      canExist: true
      params:
        name: team
        flavor: gpu-node
        cpu: 38400 # 300 węzłów × 128 rdzeni
        memory: 300Ti # 300 węzłów × 1Ti
        pods: 33000 # 300 węzłów × 110 podów
        gpu: 2400 # 300 węzłów × 8 GPU

  - id: create-local-queue
    type: SubmitObj
    params:
      refTaskId: register-local-queue
      canExist: true
      params:
        name: team-queue
        namespace: default
        clusterQueue: team

  # Group 1: High-GPU Jobs (8 GPUs per job)
  # Total resources:
  # - 1,600 CPU cores (100 × 16 = 4.17% of cluster)
  # - ~9.4Ti memory (100 × 96Gi = 3.13% of cluster)
  # - 800 GPUs (100 × 8 = 33.33% of cluster)
  - id: high-gpu-jobs
    type: SubmitObj
    params:
      refTaskId: register-job-high-gpu
      count: 100
      params:
        namespace: default
        replicas: 1
        completionMode: NonIndexed
        queueName: team-queue
        cpu: 16000m # 16 rdzeni (12.5% węzła)
        memory: 96Gi # 96GB (9.4% węzła)
        gpu: 8 # 8 GPU (100% węzła)
        ttl: 5m

  # Krótkie opóźnienie po 1 fazie
  - id: high-gpu-delay
    type: Sleep
    params:
      timeout: 15s

  # Group 2: Medium-GPU Jobs (2 GPUs per job)
  # Total resources:
  # - 800 CPU cores (100 × 8 = 2.08% of cluster)
  # - ~3.13Ti memory (100 × 32Gi = 1.04% of cluster)
  # - 200 GPUs (100 × 2 = 8.33% of cluster)
  - id: medium-gpu-jobs
    type: SubmitObj
    params:
      refTaskId: register-job-medium-gpu
      count: 100
      params:
        namespace: default
        replicas: 1
        completionMode: NonIndexed
        queueName: team-queue
        cpu: 8000m # 8 rdzeni (6.25% węzła)
        memory: 32Gi # 32GB (3.1% węzła)
        gpu: 2 # 2 GPU (25% węzła)
        ttl: 5m

  # Krótkie opóźnienie po 2 fazie
  - id: medium-gpu-delay
    type: Sleep
    params:
      timeout: 15s

  # Group 3: CPU-Only Jobs (no GPUs)
  # Total resources:
  # - 3,200 CPU cores (100 × 32 = 8.33% of cluster)
  # - ~12.5Ti memory (100 × 128Gi = 4.17% of cluster)
  # - 0 GPUs
  - id: cpu-only-jobs
    type: SubmitObj
    params:
      refTaskId: register-job-cpu-only
      count: 100
      params:
        namespace: default
        replicas: 1
        completionMode: NonIndexed
        queueName: team-queue
        cpu: 32000m # 32 rdzenie (25% węzła)
        memory: 128Gi # 128GB (12.5% węzła)
        gpu: 0 # Bez GPU
        ttl: 5m
# Total cluster utilization:
# - 5,600 CPU cores (14.58% of cluster)
# - ~25Ti memory (8.33% of cluster)
# - 1,000 GPUs (41.67% of cluster)
