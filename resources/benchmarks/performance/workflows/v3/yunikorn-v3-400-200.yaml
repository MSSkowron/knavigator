name: yunikorn-performance-benchmark-v3-400-200
description: |
  Performance benchmark for YuniKorn with diverse workloads.
  This tests the scheduler's ability to handle heterogeneous job types
  with different resource requirements simultaneously.
tasks:
  # Configure YuniKorn
  - id: configure-yunikorn
    type: Configure
    params:
      configmaps:
        - name: yunikorn-configs
          namespace: yunikorn
          op: create
          data:
            queues.yaml: |
              partitions:
                - name: default
                  queues:
                  - name: root
                    queues:
                    - name: perf-benchmark
                      submitacl: '*'
                      resources:
                        guaranteed:
                          memory: 10Gi
                          vcore: 10000m
                          nvidia.com/gpu: 100
                        max:
                          memory: 400Ti        # 1Ti × 400 nodes
                          vcore: 51200000m     # 128 cores × 400 nodes
                          nvidia.com/gpu: 3200 # 8 GPUs × 400 nodes
      deploymentRestarts:
        - namespace: yunikorn
          name: yunikorn-scheduler
      timeout: 10m

  # Configure nodes
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 400
          labels:
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: 128100m
            memory: 1048626Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Register job templates for different types
  - id: register-high-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "high-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.replicas}}"

  - id: register-medium-gpu
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "medium-gpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.replicas}}"

  - id: register-cpu-only
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/yunikorn/job.yaml"
      nameFormat: "cpu-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-.*"
      podCount: "{{.replicas}}"

  # --- Submit All Job Groups Simultaneously using Parallel Task ---
  - id: submit-all-jobs-parallel
    type: Parallel
    params:
      tasks:
        # Group 1: High-GPU Jobs (8 GPUs per job)
        - type: SubmitObj
          params:
            refTaskId: register-high-gpu
            count: 200
            params:
              namespace: default
              replicas: 1
              queue: "root.perf-benchmark"
              cpu: 16000m # 16 cores (12.5% of node)
              memory: 96Gi # 96GB (9.4% of node)
              gpu: 8 # 8 GPUs (100% of node)
              ttl: 5m

        # Group 2: Medium-GPU Jobs (2 GPUs per job)
        - type: SubmitObj
          params:
            refTaskId: register-medium-gpu
            count: 200
            params:
              namespace: default
              replicas: 1
              queue: "root.perf-benchmark"
              cpu: 8000m # 8 cores (6.25% of node)
              memory: 32Gi # 32GB (3.1% of node)
              gpu: 2 # 2 GPUs (25% of node)
              ttl: 5m

        # Group 3: CPU-Only Jobs (no GPUs)
        - type: SubmitObj
          params:
            refTaskId: register-cpu-only
            count: 200
            params:
              namespace: default
              replicas: 1
              queue: "root.perf-benchmark"
              cpu: 32000m # 32 cores (25% of node)
              memory: 128Gi # 128GB (12.5% of node)
              gpu: 0 # No GPUs
              ttl: 5m
# Total cluster utilization:
# - 11,200 CPU cores (21.88% of cluster)
# - ~50Ti memory (12.5% of cluster)
# - 2,000 GPUs (62.5% of cluster)
