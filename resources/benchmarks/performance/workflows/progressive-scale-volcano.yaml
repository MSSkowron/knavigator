# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: volcano-progressive-node-scaling
description: |
  This workflow progressively scales the number of nodes and measures
  Volcano scheduler performance at each step to identify performance inflection points.
tasks:
# Register Volcano resources
- id: register-job
  type: RegisterObj
  params:
    template: "resources/templates/volcano/job.yml"
    nameFormat: "scale-job{{._ENUM_}}"
    podNameFormat: "{{._NAME_}}-test-[0-9]+"
    podCount: "{{.replicas}}"
- id: register-configmap
  type: RegisterObj
  params:
    template: "resources/templates/k8s/configmap.yaml"

# Setup test environment with Volcano configuration
- id: configure-test-env
  type: Configure
  params:
    namespaces:
    - name: node-scale-test
      op: create
    configmaps:
    - name: node-scaling-metrics
      namespace: node-scale-test
      op: create
      data:
        test_phase: "setup"
        start_time: "{{now}}"
    - name: volcano-scheduler-configmap
      namespace: volcano-system
      op: create
      data:
        volcano-scheduler.conf: |
          actions: "enqueue, allocate, backfill"
          tiers:
          - plugins:
            - name: priority
            - name: gang
            - name: conformance
          - plugins:
            - name: drf
            - name: predicates
            - name: proportion
            - name: nodeorder
            - name: binpack
          configurations: |-
            - plugins:
              - name: proportion
                arguments:
                  gpu.weight: 10
                  cpu.weight: 3
                  memory.weight: 1
    deploymentRestarts:
    - namespace: volcano-system
      name: volcano-scheduler
    - namespace: volcano-system
      name: volcano-controllers
    timeout: 2m

# Stage 1: 50 nodes
- id: update-test-phase-50
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_50"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-50-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

- id: deploy-50-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      replicas: 45  # Leave some headroom
      priorityClassName: "normal-priority"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-50-node-job
  type: CheckPod
  params:
    refTaskId: deploy-50-node-job
    status: Running
    timeout: 2m

- id: record-50-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_50_completion_time: "{{now}}"
        nodes_50_scheduling_success: "true"
    timeout: 5s

# Stage 2: 100 nodes
- id: update-test-phase-100
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_100"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-100-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50  # Adding 50 more to existing 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

- id: deploy-100-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      replicas: 90  # Leave some headroom
      priorityClassName: "normal-priority"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-100-node-job
  type: CheckPod
  params:
    refTaskId: deploy-100-node-job
    status: Running
    timeout: 3m

- id: record-100-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_100_completion_time: "{{now}}"
        nodes_100_scheduling_success: "true"
    timeout: 5s

# Stage 3: 250 nodes
- id: update-test-phase-250
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_250"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-250-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 150  # Adding 150 more to existing 100
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 3m

- id: deploy-250-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      replicas: 225  # Leave some headroom
      priorityClassName: "normal-priority"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "45s"

- id: wait-250-node-job
  type: CheckPod
  params:
    refTaskId: deploy-250-node-job
    status: Running
    timeout: 5m

- id: record-250-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_250_completion_time: "{{now}}"
        nodes_250_scheduling_success: "true"
    timeout: 5s

# Stage 4: 500 nodes
- id: update-test-phase-500
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_500"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-500-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 250  # Adding 250 more to existing 250
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

- id: deploy-500-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      replicas: 450  # Leave some headroom
      priorityClassName: "normal-priority"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "60s"

- id: wait-500-node-job
  type: CheckPod
  params:
    refTaskId: deploy-500-node-job
    status: Running
    timeout: 8m

- id: record-500-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_500_completion_time: "{{now}}"
        nodes_500_scheduling_success: "true"
    timeout: 5s

# Stage 5: 700 nodes (full test)
- id: update-test-phase-700
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_700"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-700-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 200  # Adding 200 more to existing 500
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

- id: deploy-700-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      replicas: 650  # Leave some headroom
      priorityClassName: "normal-priority"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "90s"

- id: wait-700-node-job
  type: CheckPod
  params:
    refTaskId: deploy-700-node-job
    status: Running
    timeout: 10m

- id: record-700-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_700_completion_time: "{{now}}"
        nodes_700_scheduling_success: "true"
        test_phase: "completed"
    timeout: 5s

# Generate summary
- id: check-final-metrics
  type: CheckConfigmap
  params:
    name: node-scaling-metrics
    namespace: node-scale-test
    op: subset
    data:
      test_phase: "completed"