# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: kueue-progressive-node-scaling
description: |
  This workflow progressively scales the number of nodes and measures
  Kueue scheduler performance at each step to identify performance inflection points.
tasks:
# Register Kueue resources
- id: register-cluster-queue
  type: RegisterObj
  params:
    template: "resources/templates/kueue/cluster-queue.yaml"
- id: register-local-queue
  type: RegisterObj
  params:
    template: "resources/templates/kueue/local-queue.yaml"
- id: register-resource-flavor
  type: RegisterObj
  params:
    template: "resources/templates/kueue/resource-flavor.yaml"
- id: register-job
  type: RegisterObj
  params:
    template: "resources/templates/kueue/job.yaml"
    nameFormat: "scale-job{{._ENUM_}}"
    podNameFormat: "{{._NAME_}}-[0-9]-.*"
    podCount: "{{.parallelism}}"
- id: register-configmap
  type: RegisterObj
  params:
    template: "resources/templates/k8s/configmap.yaml"

# Setup test environment with Kueue configuration
- id: configure-test-env
  type: Configure
  params:
    namespaces:
    - name: node-scale-test
      op: create
    configmaps:
    - name: node-scaling-metrics
      namespace: node-scale-test
      op: create
      data:
        test_phase: "setup"
        start_time: "{{now}}"
    - name: kueue-manager-config
      namespace: kueue-system
      op: create
      data:
        controller_manager_config.yaml: |
          apiVersion: config.kueue.x-k8s.io/v1beta1
          kind: Configuration
          health:
            healthProbeBindAddress: :8081
          metrics:
            bindAddress: :8080
          webhook:
            port: 9443
          leaderElection:
            leaderElect: true
          controller:
            groupKindConcurrency:
              Job.batch: 10
              Pod: 10
              Workload.kueue.x-k8s.io: 10
              LocalQueue.kueue.x-k8s.io: 2
              ClusterQueue.kueue.x-k8s.io: 2
              ResourceFlavor.kueue.x-k8s.io: 2
          clientConnection:
            qps: 100
            burst: 200
          waitForPodsReady:
            enable: true
            timeout: 5m
    deploymentRestarts:
    - namespace: kueue-system
      name: kueue-controller-manager
    timeout: 2m

# Create resource flavor for Kueue
- id: create-resource-flavor
  type: SubmitObj
  params:
    refTaskId: register-resource-flavor
    canExist: true
    params:
      name: "gpu-node"
      nodeLabels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"

# Stage 1: 50 nodes
- id: update-test-phase-50
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_50"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-50-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

# Create ClusterQueue for 50 nodes
- id: create-cluster-queue-50
  type: SubmitObj
  params:
    refTaskId: register-cluster-queue
    canExist: true
    params:
      name: node-scale-queue
      flavor: gpu-node
      cpu: 8000m
      memory: 100Gi
      pods: 100
      gpu: 400

# Create LocalQueue for 50 nodes
- id: create-local-queue-50
  type: SubmitObj
  params:
    refTaskId: register-local-queue
    canExist: true
    params:
      name: node-scale-local-queue
      namespace: node-scale-test
      clusterQueue: node-scale-queue

- id: deploy-50-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 45  # Leave some headroom
      completions: 45
      queueName: node-scale-local-queue
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-50-node-job
  type: CheckPod
  params:
    refTaskId: deploy-50-node-job
    status: Running
    timeout: 2m

- id: record-50-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_50_completion_time: "{{now}}"
        nodes_50_scheduling_success: "true"
    timeout: 5s

# Stage 2: 100 nodes
- id: update-test-phase-100
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_100"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-100-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50  # Adding 50 more to existing 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

# Update ClusterQueue for 100 nodes
- id: update-cluster-queue-100
  type: SubmitObj
  params:
    refTaskId: register-cluster-queue
    canExist: true
    params:
      name: node-scale-queue
      flavor: gpu-node
      cpu: 16000m
      memory: 200Gi
      pods: 200
      gpu: 800

- id: deploy-100-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 90  # Leave some headroom
      completions: 90
      queueName: node-scale-local-queue
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-100-node-job
  type: CheckPod
  params:
    refTaskId: deploy-100-node-job
    status: Running
    timeout: 3m

- id: record-100-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_100_completion_time: "{{now}}"
        nodes_100_scheduling_success: "true"
    timeout: 5s

# Stage 3: 250 nodes
- id: update-test-phase-250
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_250"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-250-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 150  # Adding 150 more to existing 100
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 3m

# Update ClusterQueue for 250 nodes
- id: update-cluster-queue-250
  type: SubmitObj
  params:
    refTaskId: register-cluster-queue
    canExist: true
    params:
      name: node-scale-queue
      flavor: gpu-node
      cpu: 40000m
      memory: 500Gi
      pods: 500
      gpu: 2000

- id: deploy-250-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 225  # Leave some headroom
      completions: 225
      queueName: node-scale-local-queue
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "45s"

- id: wait-250-node-job
  type: CheckPod
  params:
    refTaskId: deploy-250-node-job
    status: Running
    timeout: 5m

- id: record-250-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_250_completion_time: "{{now}}"
        nodes_250_scheduling_success: "true"
    timeout: 5s

# Stage 4: 500 nodes
- id: update-test-phase-500
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_500"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-500-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 250  # Adding 250 more to existing 250
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

# Update ClusterQueue for 500 nodes
- id: update-cluster-queue-500
  type: SubmitObj
  params:
    refTaskId: register-cluster-queue
    canExist: true
    params:
      name: node-scale-queue
      flavor: gpu-node
      cpu: 80000m
      memory: 1000Gi
      pods: 1000
      gpu: 4000

- id: deploy-500-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 450  # Leave some headroom
      completions: 450
      queueName: node-scale-local-queue
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "60s"

- id: wait-500-node-job
  type: CheckPod
  params:
    refTaskId: deploy-500-node-job
    status: Running
    timeout: 8m

- id: record-500-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_500_completion_time: "{{now}}"
        nodes_500_scheduling_success: "true"
    timeout: 5s

# Stage 5: 700 nodes (full test)
- id: update-test-phase-700
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_700"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-700-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 200  # Adding 200 more to existing 500
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

# Update ClusterQueue for 700 nodes
- id: update-cluster-queue-700
  type: SubmitObj
  params:
    refTaskId: register-cluster-queue
    canExist: true
    params:
      name: node-scale-queue
      flavor: gpu-node
      cpu: 112000m
      memory: 1400Gi
      pods: 1400
      gpu: 5600

- id: deploy-700-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 650  # Leave some headroom
      completions: 650
      queueName: node-scale-local-queue
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "90s"

- id: wait-700-node-job
  type: CheckPod
  params:
    refTaskId: deploy-700-node-job
    status: Running
    timeout: 10m

- id: record-700-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_700_completion_time: "{{now}}"
        nodes_700_scheduling_success: "true"
        test_phase: "completed"
    timeout: 5s

# Generate summary
- id: check-final-metrics
  type: CheckConfigmap
  params:
    name: node-scaling-metrics
    namespace: node-scale-test
    op: subset
    data:
      test_phase: "completed"