# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: yunikorn-progressive-node-scaling
description: |
  This workflow progressively scales the number of nodes and measures
  YuniKorn scheduler performance at each step to identify performance inflection points.
tasks:
# Register YuniKorn resources
- id: register-job
  type: RegisterObj
  params:
    template: "resources/templates/yunikorn/job.yml"
    nameFormat: "scale-job{{._ENUM_}}"
    podNameFormat: "{{._NAME_}}-.*"
    podCount: "{{.parallelism}}"
- id: register-configmap
  type: RegisterObj
  params:
    template: "resources/templates/k8s/configmap.yaml"

# Setup test environment with YuniKorn configuration
- id: configure-test-env
  type: Configure
  params:
    namespaces:
    - name: node-scale-test
      op: create
    configmaps:
    - name: node-scaling-metrics
      namespace: node-scale-test
      op: create
      data:
        test_phase: "setup"
        start_time: "{{now}}"
    - name: yunikorn-configs
      namespace: yunikorn
      op: create
      data:
        queues.yaml: |
          partitions:
            - name: default
              queues:
              - name: root
                queues:
                - name: node-scale-test
                  submitacl: '*'
                  resources:
                    guaranteed:
                      memory: 1Gi
                      vcore: 1000m
                      nvidia.com/gpu: 1
        # Performance-tuned settings for the test
        scheduler-conf.yaml: |
          partitionTriggerCoolDownSec: 1
          checkAllocatorIntervalSec: 3
          schedulingIntervalSec: 1
          volumeBindingTimeoutSec: 10
          enableForcefulNodeRemoval: true
    deploymentRestarts:
    - namespace: yunikorn
      name: yunikorn-scheduler
    timeout: 2m

# Stage 1: 50 nodes
- id: update-test-phase-50
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_50"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-50-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

# Update YuniKorn quota for 50 nodes
- id: update-queue-50
  type: ConfigMap
  params:
    name: yunikorn-configs
    namespace: yunikorn 
    data:
      queues.yaml: |
        partitions:
          - name: default
            queues:
            - name: root
              queues:
              - name: node-scale-test
                submitacl: '*'
                resources:
                  max:
                    memory: 100Gi
                    vcore: 8000m
                    nvidia.com/gpu: 400
    timeout: 1m

- id: deploy-50-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 45
      completions: 45
      applicationId: "scale-50-node"
      queue: "root.node-scale-test"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-50-node-job
  type: CheckPod
  params:
    refTaskId: deploy-50-node-job
    status: Running
    timeout: 2m

- id: record-50-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_50_completion_time: "{{now}}"
        nodes_50_scheduling_success: "true"
    timeout: 5s

# Stage 2: 100 nodes
- id: update-test-phase-100
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_100"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-100-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 50  # Adding 50 more to existing 50
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 2m

# Update YuniKorn quota for 100 nodes
- id: update-queue-100
  type: ConfigMap
  params:
    name: yunikorn-configs
    namespace: yunikorn 
    data:
      queues.yaml: |
        partitions:
          - name: default
            queues:
            - name: root
              queues:
              - name: node-scale-test
                submitacl: '*'
                resources:
                  max:
                    memory: 200Gi
                    vcore: 16000m
                    nvidia.com/gpu: 800
    timeout: 1m

- id: deploy-100-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 90
      completions: 90
      applicationId: "scale-100-node"
      queue: "root.node-scale-test"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "30s"

- id: wait-100-node-job
  type: CheckPod
  params:
    refTaskId: deploy-100-node-job
    status: Running
    timeout: 3m

- id: record-100-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_100_completion_time: "{{now}}"
        nodes_100_scheduling_success: "true"
    timeout: 5s

# Stage 3: 250 nodes
- id: update-test-phase-250
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_250"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-250-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 150  # Adding 150 more to existing 100
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 3m

# Update YuniKorn quota for 250 nodes
- id: update-queue-250
  type: ConfigMap
  params:
    name: yunikorn-configs
    namespace: yunikorn 
    data:
      queues.yaml: |
        partitions:
          - name: default
            queues:
            - name: root
              queues:
              - name: node-scale-test
                submitacl: '*'
                resources:
                  max:
                    memory: 500Gi
                    vcore: 40000m
                    nvidia.com/gpu: 2000
    timeout: 1m

- id: deploy-250-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 225
      completions: 225
      applicationId: "scale-250-node"
      queue: "root.node-scale-test"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "45s"

- id: wait-250-node-job
  type: CheckPod
  params:
    refTaskId: deploy-250-node-job
    status: Running
    timeout: 5m

- id: record-250-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_250_completion_time: "{{now}}"
        nodes_250_scheduling_success: "true"
    timeout: 5s

# Stage 4: 500 nodes
- id: update-test-phase-500
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_500"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-500-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 250  # Adding 250 more to existing 250
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

# Update YuniKorn quota for 500 nodes
- id: update-queue-500
  type: ConfigMap
  params:
    name: yunikorn-configs
    namespace: yunikorn 
    data:
      queues.yaml: |
        partitions:
          - name: default
            queues:
            - name: root
              queues:
              - name: node-scale-test
                submitacl: '*'
                resources:
                  max:
                    memory: 1000Gi
                    vcore: 80000m
                    nvidia.com/gpu: 4000
    timeout: 1m

- id: deploy-500-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 450
      completions: 450
      applicationId: "scale-500-node"
      queue: "root.node-scale-test"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "60s"

- id: wait-500-node-job
  type: CheckPod
  params:
    refTaskId: deploy-500-node-job
    status: Running
    timeout: 8m

- id: record-500-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_500_completion_time: "{{now}}"
        nodes_500_scheduling_success: "true"
    timeout: 5s

# Stage 5: 700 nodes (full test)
- id: update-test-phase-700
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        test_phase: "nodes_700"
        start_time: "{{now}}"
    timeout: 5s

- id: configure-700-nodes
  type: Configure
  params:
    nodes:
    - type: dgxa100.80g
      count: 200  # Adding 200 more to existing 500
      labels:
        nvidia.com/gpu.count: "8"
        node-scale-test: "true"
    timeout: 5m

# Update YuniKorn quota for 700 nodes
- id: update-queue-700
  type: ConfigMap
  params:
    name: yunikorn-configs
    namespace: yunikorn 
    data:
      queues.yaml: |
        partitions:
          - name: default
            queues:
            - name: root
              queues:
              - name: node-scale-test
                submitacl: '*'
                resources:
                  max:
                    memory: 1400Gi
                    vcore: 112000m
                    nvidia.com/gpu: 5600
    timeout: 1m

- id: deploy-700-node-job
  type: SubmitObj
  params:
    refTaskId: register-job
    count: 1
    params:
      namespace: node-scale-test
      parallelism: 650
      completions: 650
      applicationId: "scale-700-node"
      queue: "root.node-scale-test"
      image: ubuntu
      cpu: 100m
      memory: 128Mi
      gpu: 8
      ttl: "90s"

- id: wait-700-node-job
  type: CheckPod
  params:
    refTaskId: deploy-700-node-job
    status: Running
    timeout: 10m

- id: record-700-node-metrics
  type: UpdateObj
  params:
    refTaskId: register-configmap
    state:
      data:
        nodes_700_completion_time: "{{now}}"
        nodes_700_scheduling_success: "true"
        test_phase: "completed"
    timeout: 5s

# Generate summary
- id: check-final-metrics
  type: CheckConfigmap
  params:
    name: node-scaling-metrics
    namespace: node-scale-test
    op: subset
    data:
      test_phase: "completed"