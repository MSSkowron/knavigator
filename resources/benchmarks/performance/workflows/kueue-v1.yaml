name: kueue-performance-benchmark
description: |
  TODO
tasks:
  # Configure nodes
  - id: configure
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 700
          labels:
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: 128
            memory: "1Ti"
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Configure Kueue
  - id: configure
    type: Configure
    params:
      configmaps:
        - name: kueue-manager-config
          namespace: kueue-system
          op: create
          data:
            controller_manager_config.yaml: |
              apiVersion: config.kueue.x-k8s.io/v1beta1
              kind: Configuration
              health:
                healthProbeBindAddress: :8081
              metrics:
                bindAddress: :8080
              # enableClusterQueueResources: true
              webhook:
                port: 9443
              leaderElection:
                leaderElect: true
                resourceName: c1f6bfd2.kueue.x-k8s.io
              controller:
                groupKindConcurrency:
                  Job.batch: 5
                  Pod: 5
                  Workload.kueue.x-k8s.io: 5
                  LocalQueue.kueue.x-k8s.io: 1
                  ClusterQueue.kueue.x-k8s.io: 1
                  ResourceFlavor.kueue.x-k8s.io: 1
              clientConnection:
                qps: 50
                burst: 100
              #pprofBindAddress: :8083
              waitForPodsReady:
                enable: true
                timeout: 5m
                blockAdmission: true
                requeuingStrategy:
                  timestamp: Eviction
                  backoffLimitCount: null # null indicates infinite requeuing
                  backoffBaseSeconds: 60
                  backoffMaxSeconds: 3600
              #manageJobsWithoutQueueName: true
              #internalCertManagement:
              #  enable: false
              #  webhookServiceName: ""
              #  webhookSecretName: ""
              integrations:
                frameworks:
                - "batch/job"
                - "kubeflow.org/mpijob"
                - "ray.io/rayjob"
                - "ray.io/raycluster"
                - "jobset.x-k8s.io/jobset"
                - "kubeflow.org/mxjob"
                - "kubeflow.org/paddlejob"
                - "kubeflow.org/pytorchjob"
                - "kubeflow.org/tfjob"
                - "kubeflow.org/xgboostjob"
              #  - "pod"
              #  externalFrameworks:
              #  - "Foo.v1.example.com"
              #  podOptions:
              #    namespaceSelector:
              #      matchExpressions:
              #        - key: kubernetes.io/metadata.name
              #          operator: NotIn
              #          values: [ kube-system, kueue-system ]
              #fairSharing:
              #  enable: true
              #  preemptionStrategies: [LessThanOrEqualToFinalShare, LessThanInitialShare]
              #resources:
              #  excludeResourcePrefixes: []
      deploymentRestarts:
        - namespace: kueue-system
          name: kueue-controller-manager
      timeout: 10m

  # Register Kueue-specific resources
  - id: register-cluster-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/cluster-queue.yaml"
  - id: register-local-queue
    type: RegisterObj
    params:
      template: "resources/templates/kueue/local-queue.yaml"
  - id: register-resource-flavor
    type: RegisterObj
    params:
      template: "resources/templates/kueue/resource-flavor.yaml"
  - id: register-job
    type: RegisterObj
    params:
      template: "resources/benchmarks/performance/templates/kueue/job.yaml"
      nameFormat: "perftest-v1-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-[0-9]-.*"
      podCount: "{{.parallelism}}"

  # Submit Kueue-specific resources
  - id: create-resource-flavor
    type: SubmitObj
    params:
      refTaskId: register-resource-flavor
      canExist: true
      params:
        name: "gpu-node"
        nodeLabels:
          nvidia.com/gpu.count: "8"
  - id: create-cluster-queue
    type: SubmitObj
    params:
      refTaskId: register-cluster-queue
      canExist: true
      params:
        name: team
        flavor: gpu-node
        cpu: 89600 # 700 nodes with 128 CPU each
        memory: 700Ti # 700 nodes with 1Ti each
        pods: 77000 # 700 nodes with 110 pods each
        gpu: 5600 # 700 nodes with 8 GPUs each
  - id: create-local-queue
    type: SubmitObj
    params:
      refTaskId: register-local-queue
      canExist: true
      params:
        name: team-queue
        namespace: default
        clusterQueue: team

  # Submit 700 separate jobs, each creating 1 pod
  # CPU = 700 jobs × 16 cores (16000m) = 11,200 cores total (12.5% z 89,600)
  # Memory = 700 jobs × 256Gi = 179,200Gi = ~175Ti total (25% z 700Ti)
  # GPU = 700 jobs × 4 GPU = 2,800 GPUs total (50% z 5,600)
  - id: job
    type: SubmitObj
    params:
      refTaskId: register-job
      count: 700
      params:
        namespace: default
        replicas: 1
        completionMode: NonIndexed
        queueName: team-queue
        image: ubuntu
        cpu: 16000m # 16 rdzeni (12.5% węzła CPU)
        memory: 256Gi # 256GB (25% węzła)
        gpu: 4 # 4 GPU (50% węzła GPU)
        ttl: 5m
