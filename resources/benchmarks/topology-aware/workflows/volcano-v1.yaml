name: volcano-topology-aware-benchmark
description: |
  Test Volcano's Network Topology Aware Scheduling capabilities.
  This benchmark verifies Volcano's ability to schedule pods based on network topology
  for optimal performance of distributed workloads.

  The benchmark creates a 16-node cluster with a tree-like network topology and marks 7 nodes as busy:
            __________ sw31 _________________________               - 4
           /            |             \              \
       sw21            sw22            sw23           sw24          - 3
       /  \            /  \            /  \          /    \
   sw11    sw12    sw13    sw14    sw15    sw16     sw17   sw18     - 2
    /\      /\      /\      /\      /\      /\      /  \   /  \
  n1  n2  n3  n4  n5  n6  n7  n8  n9 n10 n11 n12   n13 n14 n15 n16  - 1
  x       x       ^^  x   ^^  ^^         x   x         x       x

  Then deploy a 3-replicas job. The optimal nodes from the
  network topology perspective for this job are nodes n5, n7, n8.

  IMPORTANT: Before running this benchmark, make sure to deploy Volcano with
  Network Topology Aware Scheduling enabled using the command:
  helm upgrade --install volcano volcano-sh/volcano -n volcano-system --create-namespace --version="1.11.0-network-topology-preview.0"
tasks:
  # Configure Volcano
  - id: configure-volcano
    type: Configure
    params:
      configmaps:
        - name: volcano-scheduler-configmap
          namespace: volcano-system
          op: create
          data:
            volcano-scheduler.conf: |
              actions: "enqueue, allocate, backfill"
              tiers:
              - plugins:
                - name: priority
                - name: gang
              - plugins:
                - name: predicates
                - name: proportion
                - name: nodeorder
                - name: binpack
      deploymentRestarts:
        - namespace: volcano-system
          name: volcano-scheduler
      timeout: 10m

  # Configure nodes with network topology
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: hpc.gpu
          count: 1
          namePrefix: n1
          labels:
            network.topology.kubernetes.io/block: sw11
            network.topology.kubernetes.io/spine: sw21
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n2
          labels:
            network.topology.kubernetes.io/block: sw11
            network.topology.kubernetes.io/spine: sw21
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n3
          labels:
            network.topology.kubernetes.io/block: sw12
            network.topology.kubernetes.io/spine: sw21
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n4
          labels:
            network.topology.kubernetes.io/block: sw12
            network.topology.kubernetes.io/spine: sw21
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n5
          labels:
            ta-optimal: "true"
            network.topology.kubernetes.io/block: sw13
            network.topology.kubernetes.io/spine: sw22
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n6
          labels:
            network.topology.kubernetes.io/block: sw13
            network.topology.kubernetes.io/spine: sw22
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n7
          labels:
            ta-optimal: "true"
            network.topology.kubernetes.io/block: sw14
            network.topology.kubernetes.io/spine: sw22
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n8
          labels:
            ta-optimal: "true"
            network.topology.kubernetes.io/block: sw14
            network.topology.kubernetes.io/spine: sw22
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n9
          labels:
            network.topology.kubernetes.io/block: sw15
            network.topology.kubernetes.io/spine: sw23
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n10
          labels:
            network.topology.kubernetes.io/block: sw15
            network.topology.kubernetes.io/spine: sw23
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n11
          labels:
            network.topology.kubernetes.io/block: sw16
            network.topology.kubernetes.io/spine: sw23
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n12
          labels:
            network.topology.kubernetes.io/block: sw16
            network.topology.kubernetes.io/spine: sw23
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n13
          labels:
            network.topology.kubernetes.io/block: sw17
            network.topology.kubernetes.io/spine: sw24
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n14
          labels:
            network.topology.kubernetes.io/block: sw17
            network.topology.kubernetes.io/spine: sw24
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n15
          labels:
            network.topology.kubernetes.io/block: sw18
            network.topology.kubernetes.io/spine: sw24
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
        - type: hpc.gpu
          count: 1
          namePrefix: n16
          labels:
            network.topology.kubernetes.io/block: sw18
            network.topology.kubernetes.io/spine: sw24
            network.topology.kubernetes.io/datacenter: sw31
            nvidia.com/gpu.count: "8"
            nvidia.com/mlnxnics: "16"
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          resources:
            cpu: "256100m" # 256CPU + 100m
            memory: "2097202Mi" # 2Ti + 50Mi
            pods: 110
            nvidia.com/gpu: 8
            nvidia.com/mlnxnics: 16
            hugepages-1Gi: 0
            hugepages-2Mi: 0
            ephemeral-storage: "30Ti"
      timeout: 5m

  # Mark some nodes as unschedulable
  - id: update-nodes
    type: UpdateNodes
    params:
      selectors:
        - kubernetes.io/hostname: n1 # Unschedulable
        - kubernetes.io/hostname: n3 # Unschedulable
        - kubernetes.io/hostname: n6 # Unschedulable
        - kubernetes.io/hostname: n11 # Unschedulable
        - kubernetes.io/hostname: n12 # Unschedulable
        - kubernetes.io/hostname: n14 # Unschedulable
        - kubernetes.io/hostname: n16 # Unschedulable
      state:
        spec:
          unschedulable: true
      timeout: 2m

  # Define HyperNodes for the network topology
  - id: register-hypernode
    type: RegisterObj
    params:
      template: "resources/benchmarks/topology-aware/templates/volcano/hypernode.yaml"

  # Register job template
  - id: register-job-soft
    type: RegisterObj
    params:
      template: "resources/benchmarks/topology-aware/templates/volcano/job.yaml"
      nameFormat: "volcano-tas-job-soft{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  - id: register-job-hard
    type: RegisterObj
    params:
      template: "resources/benchmarks/topology-aware/templates/volcano/job.yaml"
      nameFormat: "volcano-tas-job-hard{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  # --- TIER 1: Create Leaf HyperNodes for individual nodes ---
  - id: create-leaf-hypernode-n1
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n1-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n1
  - id: create-leaf-hypernode-n2
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n2-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n2
  - id: create-leaf-hypernode-n3
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n3-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n3
  - id: create-leaf-hypernode-n4
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n4-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n4
  - id: create-leaf-hypernode-n5
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n5-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n5
  - id: create-leaf-hypernode-n6
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n6-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n6
  - id: create-leaf-hypernode-n7
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n7-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n7
  - id: create-leaf-hypernode-n8
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n8-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n8
  - id: create-leaf-hypernode-n9
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n9-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n9
  - id: create-leaf-hypernode-n10
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n10-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n10
  - id: create-leaf-hypernode-n11
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n11-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n11
  - id: create-leaf-hypernode-n12
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n12-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n12
  - id: create-leaf-hypernode-n13
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n13-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n13
  - id: create-leaf-hypernode-n14
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n14-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n14
  - id: create-leaf-hypernode-n15
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n15-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n15
  - id: create-leaf-hypernode-n16
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: n16-hn
        tier: 1
        members:
          - type: Node
            exactMatch: n16

  # --- TIER 2: Create Block HyperNodes grouping leaf hypernodes ---
  - id: create-hypernode-sw11
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw11
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n1-hn
          - type: HyperNode
            exactMatch: n2-hn

  - id: create-hypernode-sw12
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw12
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n3-hn
          - type: HyperNode
            exactMatch: n4-hn

  - id: create-hypernode-sw13
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw13
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n5-hn
          - type: HyperNode
            exactMatch: n6-hn

  - id: create-hypernode-sw14
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw14
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n7-hn
          - type: HyperNode
            exactMatch: n8-hn

  - id: create-hypernode-sw15
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw15
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n9-hn
          - type: HyperNode
            exactMatch: n10-hn

  - id: create-hypernode-sw16
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw16
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n11-hn
          - type: HyperNode
            exactMatch: n12-hn

  - id: create-hypernode-sw17
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw17
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n13-hn
          - type: HyperNode
            exactMatch: n14-hn

  - id: create-hypernode-sw18
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw18
        tier: 2
        members:
          - type: HyperNode
            exactMatch: n15-hn
          - type: HyperNode
            exactMatch: n16-hn

  # --- TIER 3: Create Spine layer HyperNodes ---
  - id: create-hypernode-sw21
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw21
        tier: 3
        members:
          - type: HyperNode
            exactMatch: sw11
          - type: HyperNode
            exactMatch: sw12

  - id: create-hypernode-sw22
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw22
        tier: 3
        members:
          - type: HyperNode
            exactMatch: sw13
          - type: HyperNode
            exactMatch: sw14

  - id: create-hypernode-sw23
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw23
        tier: 3
        members:
          - type: HyperNode
            exactMatch: sw15
          - type: HyperNode
            exactMatch: sw16

  - id: create-hypernode-sw24
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw24
        tier: 3
        members:
          - type: HyperNode
            exactMatch: sw17
          - type: HyperNode
            exactMatch: sw18

  # --- TIER 4: Create datacenter layer HyperNode ---
  - id: create-hypernode-sw31
    type: SubmitObj
    params:
      refTaskId: register-hypernode
      params:
        name: sw31
        tier: 4
        members:
          - type: HyperNode
            exactMatch: sw21
          - type: HyperNode
            exactMatch: sw22
          - type: HyperNode
            exactMatch: sw23
          - type: HyperNode
            exactMatch: sw24

  # Submit a job with network topology constraints (hard mode)
  - id: job-hard
    type: SubmitObj
    params:
      refTaskId: register-job-hard
      count: 1
      params:
        namespace: default
        replicas: 3
        minAvailable: 3
        queue: default
        cpu: 16000m
        memory: 32768Mi
        gpu: 8
        ttl: "1m"
        networkTopology: true
        topologyMode: hard
        highestTierAllowed: 3

  # Check if pods are running on the optimal nodes
  - id: status-running-required
    type: CheckPod
    description: confirm that the pods initiated by the job are running on optimal nodes
    params:
      refTaskId: job-hard
      status: Running
      # nodeLabels:
      #   ta-optimal: "true"
      timeout: 5m

  # Oczekiwanie, aż pody się zakończą
  - id: status-succeeded-required
    type: CheckPod
    description: waiting for the pods to finish
    params:
      refTaskId: job-hard
      status: Succeeded
      timeout: 5m

  # Krótkie opóźnienie po 1 fazie
  - id: job-delay
    type: Sleep
    params:
      timeout: 5s

  # Submit a job with network topology constraints (soft mode)
  - id: job-soft
    type: SubmitObj
    params:
      refTaskId: register-job-soft
      count: 1
      params:
        namespace: default
        replicas: 3
        minAvailable: 3
        queue: default
        cpu: 16000m
        memory: 32768Mi
        gpu: 8
        ttl: "1m"
        networkTopology: true
        topologyMode: soft
        highestTierAllowed: 3

  # Check if pods are running on the optimal nodes
  - id: status-running-preferred
    type: CheckPod
    description: confirm that the pods initiated by the job are running on optimal nodes
    params:
      refTaskId: job-soft
      status: Running
      # nodeLabels:
      #   ta-optimal: "true"
      timeout: 5m

  # Oczekiwanie, aż pody się zakończą
  - id: status-succeeded-preferred
    type: CheckPod
    description: waiting for the pods to finish
    params:
      refTaskId: job-soft
      status: Succeeded
      timeout: 5m
