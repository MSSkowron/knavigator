name: volcano-fair-share-benchmark-v1
description: |
  Fair Share benchmark for Volcano scheduler.

  This benchmark tests whether Volcano properly implements fair resource sharing
  between queues with equal weights. The test creates three queues with equal
  weights and resource limits. The test then submits multiple jobs to all queues
  and verifies that resources are distributed fairly.

  Volcano implements fair-sharing through its DRF (Dominant Resource Fairness) plugin
  and the weight configuration in queue definitions.

  Test scenario:
  1. Configure cluster with limited CPU resources (75 CPU total)
  2. Configure Volcano with DRF plugin enabled
  3. Create three queues with equal weights
  4. Submit multiple jobs to all queues (each queue requesting 30 CPU)
  5. Verify that all queues receive an equal share of resources (~25 CPU each)
tasks:
  # Configure Volcano
  - id: configure-volcano
    type: Configure
    params:
      configmaps:
        - name: volcano-scheduler-configmap
          namespace: volcano-system
          op: create
          data:
            volcano-scheduler.conf: |
              actions: "enqueue, allocate, backfill, preempt, reclaim"
              tiers:
              - plugins:
                - name: priority
                - name: gang
              - plugins:
                - name: drf  # Dominant Resource Fairness plugin for fair sharing
                  enablePreemptable: true  # Allow preemption for fair sharing
                - name: predicates
                - name: capacity # capacity plugin must be enabled
                  enableHierarchy: true # enable hierarchical queue
                - name: nodeorder
                - name: binpack
      deploymentRestarts:
        - namespace: volcano-system
          name: volcano-scheduler
      timeout: 10m

  - id: config-sleep
    type: Sleep
    params:
      timeout: 5s

  # Configure nodes
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        - type: cpu-node
          count: 5
          resources:
            cpu: 15
            memory: "15Gi"
            pods: 110
      timeout: 5m

  # Register queue template
  - id: register-queue
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/queue.yml"

  # Register job template
  - id: register-job-a
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "a-fairshare-v1-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  # Register job template
  - id: register-job-b
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "b-fairshare-v1-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  # Register job template
  - id: register-job-c
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "c-fairshare-v1-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  # Create queues with equal weights
  - id: create-queue-a
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-a-queue"
        reclaimable: true
        weight: 100 # Equal weight
        capability:
          cpu: "75" # 75 CPU total
          memory: "75Gi" # 75Gi total

  - id: create-queue-b
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-b-queue"
        reclaimable: true
        weight: 100 # Equal weight
        capability:
          cpu: "75" # 75 CPU total
          memory: "75Gi" # 75Gi total

  - id: create-queue-c
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-c-queue"
        reclaimable: true
        weight: 100 # Equal weight
        capability:
          cpu: "75" # 75 CPU total
          memory: "75Gi" # 75Gi total

  # Submit jobs for queue A
  - id: submit-jobs-tenant-a
    type: SubmitObj
    params:
      refTaskId: register-job-a
      count: 30 # Submit 30 jobs
      params:
        namespace: default
        minAvailable: 1
        replicas: 1
        queue: tenant-a-queue
        image: ubuntu
        cpu: 1000m # Each job requests 1 CPU
        memory: 1Gi
        ttl: "5m"

  # Submit jobs for queue B
  - id: submit-jobs-tenant-b
    type: SubmitObj
    params:
      refTaskId: register-job-b
      count: 30 # Submit 30 jobs
      params:
        namespace: default
        minAvailable: 1
        replicas: 1
        queue: tenant-b-queue
        image: ubuntu
        cpu: 1000m # Each job requests 1 CPU
        memory: 1Gi
        ttl: "5m"

  # Submit jobs for queue C
  - id: submit-jobs-tenant-c
    type: SubmitObj
    params:
      refTaskId: register-job-c
      count: 30 # Submit 30 jobs
      params:
        namespace: default
        minAvailable: 1
        replicas: 1
        queue: tenant-c-queue
        image: ubuntu
        cpu: 1000m # Each job requests 1 CPU
        memory: 1Gi
        ttl: "5m"

  # # Wait for jobs to be scheduled and start running
  # - id: wait-for-scheduling
  #   type: Sleep
  #   params:
  #     timeout: 30s

  # # Check queue A has fair share of resources (should be around 25 pods running)
  # - id: check-tenant-a-active
  #   type: CheckPod
  #   params:
  #     refTaskId: submit-jobs-tenant-a
  #     status: Running
  #     timeout: 10s

  # # Check queue B has fair share of resources (should be around 25 pods running)
  # - id: check-tenant-b-active
  #   type: CheckPod
  #   params:
  #     refTaskId: submit-jobs-tenant-b
  #     status: Running
  #     timeout: 10s

  # # Check queue C has fair share of resources (should be around 25 pods running)
  # - id: check-tenant-c-active
  #   type: CheckPod
  #   params:
  #     refTaskId: submit-jobs-tenant-c
  #     status: Running
  #     timeout: 10s

  # # Verify that all queues have approximately equal number of running pods (~25 each)
  # # For now, we can manually verify by checking the logs or using kubectl
  # - id: pause-for-verification
  #   type: Pause
