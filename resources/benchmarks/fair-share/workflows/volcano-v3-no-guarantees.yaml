name: volcano-fair-share-benchmark-v3
description: |
  Fair Share benchmark dla schedulera Volcano w środowisku heterogenicznym.

  Test sprawdza, czy Volcano prawidłowo implementuje mechanizm DRF (Dominant Resource Fairness)
  w heterogenicznym klastrze z węzłami o różnych profilach zasobów. Tworzy trzy oddzielne
  przestrzenie nazw i kolejki z równymi wagami, ale różnymi dominującymi zasobami.

  Scenariusz testu:
  1. Konfiguracja heterogenicznego klastra z 12 węzłami o różnych profilach zasobów
  2. Konfiguracja Volcano z włączonym pluginem DRF
  3. Utworzenie trzech kolejek o równych wagach odpowiadających tenantom
  4. Sekwencyjne wysłanie zadań w trzech rundach
tasks:
  # Configure Volcano
  - id: configure-volcano
    type: Configure
    params:
      configmaps:
        - name: volcano-scheduler-configmap
          namespace: volcano-system
          op: create
          data:
            volcano-scheduler.conf: |
              actions: "enqueue, allocate, preempt, reclaim"
              tiers:
              - plugins:
                - name: priority
              - plugins:
                - name: drf
                  enablePreemptable: true
                - name: predicates
                - name: proportion
                - name: nodeorder
                - name: binpack
      deploymentRestarts:
        - namespace: volcano-system
          name: volcano-scheduler
      timeout: 10m

  - id: config-sleep
    type: Sleep
    params:
      timeout: 5s

  # Configure heterogeneous nodes
  # Cluster capacity:
  # CPU:    384000  m
  # Memory: 1536000 Mi
  # GPU:    16
  # Pods:   1320
  - id: configure-nodes
    type: Configure
    params:
      nodes:
        # Typ A: CPU-intensive (4 węzły)
        - type: cpu-node
          count: 4
          labels:
            node-type: cpu-intensive
            nvidia.com/gpu.count: "0"
          resources:
            cpu: 64100m # 64 rdzenie + 100m na system KWOK
            memory: "64050Mi" # 64GB + 50Mi na system KWOK
            pods: 110
            nvidia.com/gpu: 0

        # Typ B: RAM-intensive (4 węzły)
        - type: ram-node
          count: 4
          labels:
            node-type: ram-intensive
            nvidia.com/gpu.count: "0"
          resources:
            cpu: 16100m # 16 rdzeni + 100m na system KWOK
            memory: "256050Mi" # 256GB + 50Mi na system KWOK
            pods: 110
            nvidia.com/gpu: 0

        # Typ C: GPU-enabled (4 węzły)
        - type: gpu-node
          count: 4
          labels:
            node-type: gpu-enabled
            nvidia.com/gpu.count: "4"
          resources:
            cpu: 16100m # 16 rdzeni + 100m na system KWOK
            memory: "64050Mi" # 64GB + 50Mi na system KWOK
            pods: 110
            nvidia.com/gpu: 4
      timeout: 5m

  # Create namespaces for the three tenants
  - id: create-namespaces
    type: Configure
    params:
      namespaces:
        - name: tenant-a
          op: create
        - name: tenant-b
          op: create
        - name: tenant-c
          op: create
      timeout: 1m

  # Register queue template
  - id: register-queue
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/queue.yml"

  # Register job templates for different batches
  - id: register-job-batch-1
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "a-fairshare-v3-batch1-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  - id: register-job-batch-2
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "a-fairshare-v3-batch2-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  - id: register-job-batch-3
    type: RegisterObj
    params:
      template: "resources/benchmarks/fair-share/templates/volcano/job.yml"
      nameFormat: "a-fairshare-v3-batch3-job{{._ENUM_}}"
      podNameFormat: "{{._NAME_}}-test-[0-9]+"
      podCount: "{{.replicas}}"

  # Create queues with equal weights
  - id: create-queue-a
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-a-queue"
        reclaimable: true
        priority: 1
        weight: 1
        capability: # cluster total
          cpu: 384000m
          memory: 1536000Mi
          nvidia.com/gpu: 16

  - id: create-queue-b
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-b-queue"
        reclaimable: true
        priority: 1
        weight: 1
        capability: # cluster total
          cpu: 384000m
          memory: 1536000Mi
          nvidia.com/gpu: 16

  - id: create-queue-c
    type: SubmitObj
    params:
      refTaskId: register-queue
      canExist: true
      params:
        name: "tenant-c-queue"
        reclaimable: true
        priority: 1
        weight: 1
        capability: # cluster total
          cpu: 384000m
          memory: 1536000Mi
          nvidia.com/gpu: 16

  # Runda 1: Pierwszy batch zadań dla wszystkich najemców
  # Tenant-A: 400000 m  CPU (≈104,17% CPU klastra)
  #           400000 Mi RAM (≈26,04% RAM klastra)
  #           0         GPU (0,00% GPU klastra)
  - id: submit-jobs-tenant-a-batch1
    type: SubmitObj
    params:
      refTaskId: register-job-batch-1
      count: 100
      params:
        namespace: tenant-a
        replicas: 1
        queue: tenant-a-queue
        cpu: 4000m
        memory: 4000Mi
        ttl: "5m"

  # Tenant-B: 100000  m  CPU (≈26,04% CPU klastra)
  #           1600000 Mi RAM (≈104,17% RAM klastra)
  #           0          GPU (0,00% GPU klastra)
  - id: submit-jobs-tenant-b-batch1
    type: SubmitObj
    params:
      refTaskId: register-job-batch-1
      count: 100
      params:
        namespace: tenant-b
        replicas: 1
        queue: tenant-b-queue
        cpu: 1000m
        memory: 16000Mi
        ttl: "5m"

  # Tenant-C: 20000 m  CPU (≈5,21% CPU klastra)
  #           80000 Mi RAM (≈5,21% RAM klastra)
  #           20       GPU (≈125,00% GPU klastra)
  - id: submit-jobs-tenant-c-batch1
    type: SubmitObj
    params:
      refTaskId: register-job-batch-1
      count: 20
      params:
        namespace: tenant-c
        replicas: 1
        queue: tenant-c-queue
        cpu: 1000m
        memory: 4000Mi
        gpu: 1
        ttl: "5m"

  - id: wait-between-rounds1
    type: Sleep
    params:
      timeout: 5s

  # Runda 2: Drugi batch zadań dla wszystkich najemców
  # Tenant-A: 400000 m  CPU (≈104,17% CPU klastra)
  #           400000 Mi RAM (≈26,04% RAM klastra)
  #           0         GPU (0,00% GPU klastra)
  - id: submit-jobs-tenant-a-batch2
    type: SubmitObj
    params:
      refTaskId: register-job-batch-2
      count: 100
      params:
        namespace: tenant-a
        replicas: 1
        queue: tenant-a-queue
        cpu: 4000m
        memory: 4000Mi
        ttl: "5m"

  # Tenant-B: 100000  m  CPU (≈26,04% CPU klastra)
  #           1600000 Mi RAM (≈104,17% RAM klastra)
  #           0          GPU (0,00% GPU klastra)
  - id: submit-jobs-tenant-b-batch2
    type: SubmitObj
    params:
      refTaskId: register-job-batch-2
      count: 100
      params:
        namespace: tenant-b
        replicas: 1
        queue: tenant-b-queue
        cpu: 1000m
        memory: 16000Mi
        ttl: "5m"

  # Tenant-C: 20000 m  CPU (≈5,21% CPU klastra)
  #           80000 Mi RAM (≈5,21% RAM klastra)
  #           20       GPU (≈125,00% GPU klastra)
  - id: submit-jobs-tenant-c-batch2
    type: SubmitObj
    params:
      refTaskId: register-job-batch-2
      count: 20
      params:
        namespace: tenant-c
        replicas: 1
        queue: tenant-c-queue
        cpu: 1000m
        memory: 4000Mi
        gpu: 1
        ttl: "5m"
